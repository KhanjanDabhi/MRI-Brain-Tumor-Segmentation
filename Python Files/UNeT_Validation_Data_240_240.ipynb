{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNeT_Validation_Data_240*240.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P4h2OCk5-o6"
      },
      "source": [
        "### **This notebook generates segmentation results for validation data with input size 240*240**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM-4Xm4lriNs",
        "outputId": "95bdb3da-0aab-4846-ef5b-120ad34580d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3mIl0z2syvo",
        "outputId": "3b2a0228-1cf6-465e-8a1d-a3486d35fde2"
      },
      "source": [
        "pip install nilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.1)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->nilearn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGphatcts10H",
        "outputId": "97545d09-128a-4210-df28-8e20e11c07de"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input ,BatchNormalization , Activation ,Dropout\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D,Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import optimizers \n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.color as color\n",
        "import random as r\n",
        "import math\n",
        "from nilearn import plotting\n",
        "import pickle\n",
        "import skimage.transform as skTrans\n",
        "from nilearn import image\n",
        "from nilearn.image import resample_img\n",
        "import nibabel.processing\n",
        "import warnings\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
            "  \"Numpy arrays.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzvgh8bkxP5d"
      },
      "source": [
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/MRI Data/BraTS2020_ValidationData'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txsr6d5J7yVa"
      },
      "source": [
        "### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgM-R7s7xOAr"
      },
      "source": [
        "def Data_Preprocessing(modalities_dir):\n",
        "    all_modalities = []    \n",
        "    for modality in modalities_dir:   \n",
        "        nifti_file   = nib.load(modality)\n",
        "        brain_numpy  = np.asarray(nifti_file.dataobj)    \n",
        "        all_modalities.append(brain_numpy)\n",
        "    all_modalities = np.array(all_modalities)\n",
        "    all_modalities = np.rint(all_modalities).astype(np.int16)\n",
        "    all_modalities = all_modalities[:, :, :, :]\n",
        "    all_modalities = np.transpose(all_modalities)\n",
        "    avg_modality=[]\n",
        "    for i in range(len(all_modalities)):\n",
        "      x=(all_modalities[i,:,:,0]+all_modalities[i,:,:,1]+all_modalities[i,:,:,2]+all_modalities[i,:,:,3])/4\n",
        "      avg_modality.append(x)  \n",
        "    gt=all_modalities[:,:,:,4]\n",
        "    P_Data=np.stack(np.stack((avg_modality, gt), axis = -1))\n",
        "    #P_Data=np.stack(np.stack((avg_modality), axis = -1))#for validation dataset \n",
        "    \n",
        "    \n",
        "\n",
        "    return P_Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjNDVuyp6MRI"
      },
      "source": [
        "batch=120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrI0CEnMxJZc",
        "outputId": "08089757-0668-4432-e5fd-0a5f8cd0e39b"
      },
      "source": [
        "Path='/content/drive/MyDrive/MRI Data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'# for validation dataset \n",
        "p=os.listdir(Path)\n",
        "Input_Data= []\n",
        "\n",
        "# generate data in batches or else computationl resources get exhausted\n",
        "for i in p[batch-40:batch+5]:\n",
        "  \n",
        "    brain_dir = os.path.normpath(Path+'/'+i)\n",
        "    flair     = glob.glob(os.path.join(brain_dir, '*_flair*.nii'))\n",
        "    t1        = glob.glob(os.path.join(brain_dir, '*_t1*.nii'))\n",
        "    t1ce      = glob.glob(os.path.join(brain_dir, '*_t1ce*.nii'))\n",
        "    t2        = glob.glob(os.path.join(brain_dir, '*_t2*.nii'))\n",
        "    gt        = glob.glob( os.path.join(brain_dir, '*_seg*.nii'))\n",
        "    \n",
        "    modalities_dir = [flair[0], t1[0], t1ce[0], t2[0], gt[0]]\n",
        "    \n",
        "    P_Data = Data_Preprocessing(modalities_dir)\n",
        "    Input_Data.append(P_Data)\n",
        "    print('This is done ', i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is done  BraTS20_Validation_081\n",
            "This is done  BraTS20_Validation_082\n",
            "This is done  BraTS20_Validation_084\n",
            "This is done  BraTS20_Validation_083\n",
            "This is done  BraTS20_Validation_085\n",
            "This is done  BraTS20_Validation_086\n",
            "This is done  BraTS20_Validation_087\n",
            "This is done  BraTS20_Validation_088\n",
            "This is done  BraTS20_Validation_089\n",
            "This is done  BraTS20_Validation_090\n",
            "This is done  BraTS20_Validation_091\n",
            "This is done  BraTS20_Validation_092\n",
            "This is done  BraTS20_Validation_093\n",
            "This is done  BraTS20_Validation_095\n",
            "This is done  BraTS20_Validation_094\n",
            "This is done  BraTS20_Validation_096\n",
            "This is done  BraTS20_Validation_097\n",
            "This is done  BraTS20_Validation_098\n",
            "This is done  BraTS20_Validation_099\n",
            "This is done  BraTS20_Validation_100\n",
            "This is done  BraTS20_Validation_101\n",
            "This is done  BraTS20_Validation_102\n",
            "This is done  BraTS20_Validation_103\n",
            "This is done  BraTS20_Validation_104\n",
            "This is done  BraTS20_Validation_105\n",
            "This is done  BraTS20_Validation_106\n",
            "This is done  BraTS20_Validation_107\n",
            "This is done  BraTS20_Validation_108\n",
            "This is done  BraTS20_Validation_109\n",
            "This is done  BraTS20_Validation_110\n",
            "This is done  BraTS20_Validation_111\n",
            "This is done  BraTS20_Validation_112\n",
            "This is done  BraTS20_Validation_113\n",
            "This is done  BraTS20_Validation_114\n",
            "This is done  BraTS20_Validation_115\n",
            "This is done  BraTS20_Validation_116\n",
            "This is done  BraTS20_Validation_117\n",
            "This is done  BraTS20_Validation_118\n",
            "This is done  BraTS20_Validation_119\n",
            "This is done  BraTS20_Validation_120\n",
            "This is done  BraTS20_Validation_121\n",
            "This is done  BraTS20_Validation_122\n",
            "This is done  BraTS20_Validation_123\n",
            "This is done  BraTS20_Validation_124\n",
            "This is done  BraTS20_Validation_125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSImg4H_78XY"
      },
      "source": [
        "### **Generating Segmentation Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZ9ii_3terg"
      },
      "source": [
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "    return x\n",
        "\n",
        "def model(input_shape):\n",
        "    \n",
        "    inputs = Input((input_shape))\n",
        "    \n",
        "    conv_1 = Convolution(inputs,32)\n",
        "    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n",
        "    \n",
        "    conv_2 = Convolution(maxp_1,64)\n",
        "    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n",
        "    \n",
        "    conv_3 = Convolution(maxp_2,128)\n",
        "    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n",
        "    \n",
        "    conv_4 = Convolution(maxp_3,256)\n",
        "    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n",
        "    \n",
        "    conv_5 = Convolution(maxp_4,512)\n",
        "    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n",
        "    \n",
        "    conv_6 = Convolution(upsample_6,256)\n",
        "    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n",
        "    \n",
        "    upsample_7 = concatenate([upsample_7, conv_3])\n",
        "    \n",
        "    conv_7 = Convolution(upsample_7,128)\n",
        "    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n",
        "    \n",
        "    conv_8 = Convolution(upsample_8,64)\n",
        "    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n",
        "    \n",
        "    upsample_9 = concatenate([upsample_9, conv_1])\n",
        "    \n",
        "    conv_9 = Convolution(upsample_9,32)\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs]) \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZGIdiiYtjAq",
        "outputId": "7fd51a8c-9334-46c5-951d-7faa9c7a4451"
      },
      "source": [
        "model = model(input_shape = (240,240,1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 240, 240, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 240, 240, 32) 320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 240, 240, 32) 128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 240, 240, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 120, 120, 32) 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 120, 120, 64) 18496       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 120, 120, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 120, 120, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 60, 60, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 60, 60, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 60, 60, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 30, 30, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 30, 30, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 30, 30, 256)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 256)  0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 15, 15, 512)  1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 15, 15, 512)  2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 15, 15, 512)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 30, 30, 512)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 30, 30, 256)  1179904     up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 30, 30, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 30, 30, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 60, 60, 256)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 60, 60, 384)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 60, 60, 128)  442496      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 60, 60, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 60, 60, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 120, 120, 128 0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 120, 120, 64) 73792       up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 120, 120, 64) 256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 120, 120, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 240, 240, 64) 0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 240, 240, 96) 0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 240, 240, 32) 27680       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 240, 240, 32) 128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 240, 240, 32) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 240, 240, 1)  33          activation_8[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,297,793\n",
            "Trainable params: 3,294,849\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1J8aY2cs864"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/MRI Data/Brats2020_20Images/BraTs2020_20.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p42CqaHGvvS6"
      },
      "source": [
        "def Data_Concatenate(Input_Data):\n",
        "    counter=0\n",
        "    Output= []\n",
        "    for i in range(2):\n",
        "        print('$')\n",
        "        c=0\n",
        "        counter=0\n",
        "        for ii in range(len(Input_Data)):\n",
        "\n",
        "            if (counter < len(Input_Data)-1):\n",
        "                a= Input_Data[counter][:,:,:,i]\n",
        "                #print('a={}'.format(a.shape))\n",
        "                b= Input_Data[counter+1][:,:,:,i]\n",
        "                #print('b={}'.format(b.shape))\n",
        "                if (counter==0):\n",
        "                    c= np.concatenate((a, b), axis=0)\n",
        "                    #print('c1={}'.format(c.shape))\n",
        "                    counter= counter+2\n",
        "                else:\n",
        "                    c1= np.concatenate((a, b), axis=0)\n",
        "                    c= np.concatenate((c, c1), axis=0)\n",
        "                    print('c2={}'.format(c.shape))\n",
        "                    counter= counter+2\n",
        "            \n",
        "            if (counter == len(Input_Data)-1):\n",
        "              a= Input_Data[counter][:,:,:,i]\n",
        "              c= np.concatenate((c, a), axis=0)\n",
        "              print('c2={}'.format(c.shape))\n",
        "              counter=counter+2\n",
        "\n",
        "        print('c2={}'.format(c.shape))\n",
        "        c= c[:,:,:,np.newaxis]\n",
        "        Output.append(c)\n",
        "    return Output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TFzOvFmvxh5",
        "outputId": "bdba3bc4-df12-43c0-ff07-db0f647c28d8"
      },
      "source": [
        "InData= Data_Concatenate(Input_Data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$\n",
            "c2=(620, 240, 240)\n",
            "c2=(930, 240, 240)\n",
            "c2=(1240, 240, 240)\n",
            "c2=(1550, 240, 240)\n",
            "c2=(1860, 240, 240)\n",
            "c2=(2170, 240, 240)\n",
            "c2=(2480, 240, 240)\n",
            "c2=(2790, 240, 240)\n",
            "c2=(3100, 240, 240)\n",
            "c2=(3410, 240, 240)\n",
            "c2=(3720, 240, 240)\n",
            "c2=(4030, 240, 240)\n",
            "c2=(4340, 240, 240)\n",
            "c2=(4650, 240, 240)\n",
            "c2=(4960, 240, 240)\n",
            "c2=(5270, 240, 240)\n",
            "c2=(5580, 240, 240)\n",
            "c2=(5890, 240, 240)\n",
            "c2=(6200, 240, 240)\n",
            "c2=(6510, 240, 240)\n",
            "c2=(6820, 240, 240)\n",
            "c2=(6975, 240, 240)\n",
            "c2=(6975, 240, 240)\n",
            "$\n",
            "c2=(620, 240, 240)\n",
            "c2=(930, 240, 240)\n",
            "c2=(1240, 240, 240)\n",
            "c2=(1550, 240, 240)\n",
            "c2=(1860, 240, 240)\n",
            "c2=(2170, 240, 240)\n",
            "c2=(2480, 240, 240)\n",
            "c2=(2790, 240, 240)\n",
            "c2=(3100, 240, 240)\n",
            "c2=(3410, 240, 240)\n",
            "c2=(3720, 240, 240)\n",
            "c2=(4030, 240, 240)\n",
            "c2=(4340, 240, 240)\n",
            "c2=(4650, 240, 240)\n",
            "c2=(4960, 240, 240)\n",
            "c2=(5270, 240, 240)\n",
            "c2=(5580, 240, 240)\n",
            "c2=(5890, 240, 240)\n",
            "c2=(6200, 240, 240)\n",
            "c2=(6510, 240, 240)\n",
            "c2=(6820, 240, 240)\n",
            "c2=(6975, 240, 240)\n",
            "c2=(6975, 240, 240)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHcMb4mhv1VS"
      },
      "source": [
        "AIO= concatenate(InData, axis=3)\n",
        "AIO=np.array(AIO,dtype='float32')\n",
        "TR=np.array(AIO[:,:,:,0],dtype='float32')\n",
        "TRL=np.array(AIO[:,:,:,1],dtype='float32')#segmentation\n",
        "AIO=TRL=0\n",
        "AIO=np.array(AIO,dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-MsYLhqv4OI"
      },
      "source": [
        "#predict segmentation\n",
        "Segmentation = model.predict(TR)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU3Fw5QFv6Qs"
      },
      "source": [
        "# save segmentation results for further use\n",
        "with open('/content/drive/MyDrive/MRI Data/Brats2020_20Images/Segmentation_Output_80_125'+'.pkl','wb') as f:\n",
        "    pickle.dump(Segmentation,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGZC9LB18DaZ"
      },
      "source": [
        "### **Storing Segmentaion Results in Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxmibmWV7GEN"
      },
      "source": [
        "#converting Segmentation result back to 125 sections\n",
        "Section=[]\n",
        "previous=0\n",
        "for i in range(len(Segmentation)):\n",
        "  if (i % 155 == 0):\n",
        "    a=Segmentation[i:i+155,:,:,0]\n",
        "    Section.append(a)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMa1c5dq7H9-"
      },
      "source": [
        "Section = np.transpose(Section, (0,3,2,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi2orNFS7L_Z"
      },
      "source": [
        "x=nib.load('/content/drive/MyDrive/MRI Data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_001/BraTS20_Validation_001_flair.nii')\n",
        "target_affine=x.affine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUe3r7NX7PAl"
      },
      "source": [
        "# generate .nii.gz files\n",
        "counter=81\n",
        "for i in range(len(Section)):\n",
        " \n",
        "  data=Section[i]\n",
        "  img = nib.Nifti1Image(data, target_affine)\n",
        "  nib.save(img, '/content/drive/MyDrive/MRI Data/Brats2020_20Images/BraTS20_Validation_'+str(counter).zfill(3)+'.nii.gz')  \n",
        "  print('/content/drive/MyDrive/MRI Data/Brats2020_20Images/BraTS20_Validation_'+str(counter).zfill(3)+'.nii.gz')\n",
        "  counter=counter+1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}