{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet_For_Implementation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDUqGaDl136t"
      },
      "source": [
        "### **This notebook is used to make the UNet.py script which will run of the server side to generate segmentation results on web-interface**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AlhqKVhnskr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace18dfe-7ee1-4798-c57c-c3b47d83d226"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcZS-Aog6DhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9197850c-c184-4cee-baed-da256d505f9a"
      },
      "source": [
        "pip install nilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/bd/2ad86e2c00ecfe33b86f9f1f6d81de8e11724e822cdf1f5b2d0c21b787f1/nilearn-0.7.1-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->nilearn) (1.15.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3LOqJLnA5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65573bd1-ed52-4b87-a1f1-5e22b73ca450"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input ,BatchNormalization , Activation \n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import optimizers \n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "import glob\n",
        "import imageio\n",
        "import skimage.io as io\n",
        "import skimage.color as color\n",
        "import random as r\n",
        "import cv2\n",
        "import math\n",
        "from nilearn import plotting\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import skimage.transform as skTrans\n",
        "from nilearn import image\n",
        "from nilearn.image import resample_img\n",
        "import nibabel.processing\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
            "  \"Numpy arrays.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6WhK1mLxPaf"
      },
      "source": [
        "### **CreateModel() function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0oFPanbSpr0"
      },
      "source": [
        "\"\"\"\n",
        "rescale_Nii(nifti_file):\n",
        "This function takes a .nii files as an input and rescales it according to the \n",
        "values of voxel_dims by creating a new affine transform. The new affine transform\n",
        "is used in resample_img() function from nibable library which will transform the images\n",
        "accordinly inputs for resample_img() are tagert image, target affine transform and target shape\n",
        "\n",
        "Input:\n",
        "nifti_file: A .nii file which we want to rescale\n",
        "\n",
        "Output:\n",
        "rescaled .nii file with dimensions as defined in target_shape\n",
        "\"\"\"\n",
        "def rescale_Nii(nifti_file):\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    img=nifti_file\n",
        "    #voxel_dims=[3.8, 3.8,1]\n",
        "    voxel_dims=[1.60, 1.60,1]\n",
        "    \n",
        "\n",
        "    # downl sample to 128*128*155\n",
        "    #target_shape=(64,64,130)\n",
        "    target_shape=(128,128,155)\n",
        "    # Initialize target_affine\n",
        "    target_affine = img.affine.copy()\n",
        "    # Calculate the translation part of the affine\n",
        "    spatial_dimensions = (img.header['dim'] * img.header['pixdim'])[1:4]\n",
        "    \n",
        "    # Calculate the translation affine as a proportion of the real world\n",
        "    # spatial dimensions\n",
        "    image_center_as_prop = img.affine[0:3,3] / spatial_dimensions\n",
        "    \n",
        "    # Calculate the equivalent center coordinates in the target image\n",
        "    dimensions_of_target_image = (np.array(voxel_dims) * np.array(target_shape))\n",
        "    target_center_coords =  dimensions_of_target_image * image_center_as_prop\n",
        "    # Decompose the image affine to allow scaling\n",
        "    u,s,v = np.linalg.svd(target_affine[:3,:3],full_matrices=False)\n",
        "    \n",
        "    # Rescale the image to the appropriate voxel dimensions\n",
        "    s = voxel_dims\n",
        "    \n",
        "    # Reconstruct the affine\n",
        "    target_affine[:3,:3] = u @ np.diag(s) @ v\n",
        "\n",
        "    # Set the translation component of the affine computed from the input\n",
        "    target_affine[:3,3] = target_center_coords \n",
        "  \n",
        "\n",
        "    #target_affine = rescale_affine(target_affine,voxel_dims,target_center_coords)\n",
        "    resampled_img = resample_img(img, target_affine=target_affine,target_shape=target_shape)\n",
        "    resampled_img.header.set_zooms((np.absolute(voxel_dims)))\n",
        "    return resampled_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JspWoQBmsv7q"
      },
      "source": [
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "    return x\n",
        "\n",
        "def model(input_shape):\n",
        "    \n",
        "    inputs = Input((input_shape))\n",
        "    \n",
        "    conv_1 = Convolution(inputs,32)\n",
        "    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n",
        "    \n",
        "    conv_2 = Convolution(maxp_1,64)\n",
        "    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n",
        "    \n",
        "    conv_3 = Convolution(maxp_2,128)\n",
        "    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n",
        "    \n",
        "    conv_4 = Convolution(maxp_3,256)\n",
        "    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n",
        "    \n",
        "    conv_5 = Convolution(maxp_4,512)\n",
        "    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n",
        "    \n",
        "    conv_6 = Convolution(upsample_6,256)\n",
        "    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n",
        "    \n",
        "    upsample_7 = concatenate([upsample_7, conv_3])\n",
        "    \n",
        "    conv_7 = Convolution(upsample_7,128)\n",
        "    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n",
        "    \n",
        "    conv_8 = Convolution(upsample_8,64)\n",
        "    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n",
        "    \n",
        "    upsample_9 = concatenate([upsample_9, conv_1])\n",
        "    \n",
        "    conv_9 = Convolution(upsample_9,32)\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs]) \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTlBZpq2s6zT"
      },
      "source": [
        "# Loding the Light weighted CNN\n",
        "model = model(input_shape = (128,128,1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dJaliAxnqLg"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/MRI Data/Model_History/BraTs2020_(Fused_0-369).h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbwZ2pThxYtT"
      },
      "source": [
        "### **TumorPredict(4- array for paths of files,1-location to store the output ) function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl9sCPJrn8Bb"
      },
      "source": [
        "t1=('/content/drive/MyDrive/MRI Data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_001/BraTS20_Validation_001_t1.nii')\n",
        "t1ce=('//content/drive/MyDrive/MRI Data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_001/BraTS20_Validation_001_t1ce.nii')\n",
        "flair=('/content/drive/MyDrive/MRI Data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_001/BraTS20_Validation_001_flair.nii')\n",
        "t2=('/content/drive/MyDrive/MRI Data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_001/BraTS20_Validation_001_t2.nii')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaWgPPOmvnjy"
      },
      "source": [
        "modalities=[t1,t1ce,flair,t2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH5Gij6MtlL_"
      },
      "source": [
        "all_modalities = []    \n",
        "for modality in modalities:      \n",
        "        nifti_file   = nib.load(modality)\n",
        "        nifti_file= rescale_Nii(nifti_file)\n",
        "        brain_numpy  = np.asarray(nifti_file.dataobj)    \n",
        "        all_modalities.append(brain_numpy)\n",
        "brain_affine   = nifti_file.affine\n",
        "all_modalities = np.array(all_modalities)\n",
        "all_modalities = np.rint(all_modalities).astype(np.int16)\n",
        "all_modalities = all_modalities[:, :, :, :]\n",
        "all_modalities = np.transpose(all_modalities)\n",
        "avg_modality=[]\n",
        "for i in range(len(all_modalities)):\n",
        "    x=(all_modalities[i,:,:,0]+all_modalities[i,:,:,1]+all_modalities[i,:,:,2]+all_modalities[i,:,:,3])/4\n",
        "    avg_modality.append(x)  \n",
        "avg_modality=np.array(avg_modality)  \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVNHUf9nuiGv"
      },
      "source": [
        "TR=np.array(avg_modality[:,:,:],dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Yi1R71y1lH"
      },
      "source": [
        "pref_Tumor = model.predict(TR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwKSnvnbybyO"
      },
      "source": [
        "### **SaveOutput(location to save,pref_tumor) function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laVn75fzd1zU"
      },
      "source": [
        "# This part save the pred_Tumor array into the given file directory for each silce as a .png image\n",
        "for i in range(len(pref_Tumor)):\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  plt.title('Slice Number:'+str(i+1))\n",
        "  plt.imshow(np.squeeze(TR[i,:,:]),cmap='gray')\n",
        "  plt.imshow(np.squeeze(pref_Tumor[i,:,:,0]),alpha=0.3,cmap='Reds')\n",
        "  plt.savefig('/content/drive/MyDrive/MRI Data/Output/Slice Number: '+str(i+1).zfill(3)+'.png')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaj3gtnCn33Z"
      },
      "source": [
        "#Output the .nii file\n",
        "x=pref_Tumor[:,:,:,0]\n",
        "x = np.transpose(x, (1,2,0))\n",
        "img = nib.Nifti1Image(x, brain_affine)\n",
        "nib.save(img, '/content/drive/MyDrive/MRI Data/Output/Segmentation.nii.gz') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}